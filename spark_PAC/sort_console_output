Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/09/07 10:52:20 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 192.168.122.1 instead (on interface virbr0)
22/09/07 10:52:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
22/09/07 10:52:20 INFO SparkContext: Running Spark version 3.0.3
22/09/07 10:52:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/09/07 10:52:21 INFO ResourceUtils: ==============================================================
22/09/07 10:52:21 INFO ResourceUtils: Resources for spark.driver:

22/09/07 10:52:21 INFO ResourceUtils: ==============================================================
22/09/07 10:52:21 INFO SparkContext: Submitted application: Sort-zlib
22/09/07 10:52:21 INFO SecurityManager: Changing view acls to: root
22/09/07 10:52:21 INFO SecurityManager: Changing modify acls to: root
22/09/07 10:52:21 INFO SecurityManager: Changing view acls groups to: 
22/09/07 10:52:21 INFO SecurityManager: Changing modify acls groups to: 
22/09/07 10:52:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
22/09/07 10:52:22 INFO Utils: Successfully started service 'sparkDriver' on port 33892.
22/09/07 10:52:22 INFO SparkEnv: Registering MapOutputTracker
22/09/07 10:52:22 INFO SparkEnv: Registering BlockManagerMaster
22/09/07 10:52:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/09/07 10:52:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/09/07 10:52:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/09/07 10:52:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dbaa465f-f128-41d6-a2ac-1aefc7f644c4
22/09/07 10:52:22 INFO MemoryStore: MemoryStore started with capacity 2.9 GiB
22/09/07 10:52:22 INFO SparkEnv: Registering OutputCommitCoordinator
22/09/07 10:52:22 INFO log: Logging initialized @3074ms to org.eclipse.jetty.util.log.Slf4jLog
22/09/07 10:52:22 INFO Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_322-b06
22/09/07 10:52:22 INFO Server: Started @3169ms
22/09/07 10:52:22 INFO AbstractConnector: Started ServerConnector@1de5f0ef{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
22/09/07 10:52:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@f74e835{/jobs,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a320ade{/jobs/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7813cb11{/jobs/job,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@32f0fba8{/jobs/job/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@29ef6856{/stages,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3faf2e7d{/stages/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@569bf9eb{/stages/stage,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@eb6449b{/stages/stage/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@180e6ac4{/stages/pool,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7e985ce9{/stages/pool/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@410ae9a3{/storage,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d5ae57e{/storage/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7e242b4d{/storage/rdd,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@592e843a{/storage/rdd/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@423e4cbb{/environment,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@43b4fe19{/environment/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1536602f{/executors,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2a1edad4{/executors/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44c79f32{/executors/threadDump,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@235f4c10{/executors/threadDump/json,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@c7a975a{/static,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@165b8a71{/,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f058b8a{/api,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@64337702{/jobs/job/kill,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30ea8c23{/stages/stage/kill,null,AVAILABLE,@Spark}
22/09/07 10:52:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.122.1:4040
22/09/07 10:52:22 INFO Executor: Starting executor ID driver on host 192.168.122.1
22/09/07 10:52:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35602.
22/09/07 10:52:22 INFO NettyBlockTransferService: Server created on 192.168.122.1:35602
22/09/07 10:52:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/09/07 10:52:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.122.1, 35602, None)
22/09/07 10:52:22 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.122.1:35602 with 2.9 GiB RAM, BlockManagerId(driver, 192.168.122.1, 35602, None)
22/09/07 10:52:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.122.1, 35602, None)
22/09/07 10:52:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.122.1, 35602, None)
22/09/07 10:52:22 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@71ea1fda{/metrics/json,null,AVAILABLE,@Spark}
22/09/07 10:52:23 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/zcp/spark_experiments/spark_hw/spark-3.0.3/spark-warehouse').
22/09/07 10:52:23 INFO SharedState: Warehouse path is 'file:/home/zcp/spark_experiments/spark_hw/spark-3.0.3/spark-warehouse'.
22/09/07 10:52:23 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1e63d216{/SQL,null,AVAILABLE,@Spark}
22/09/07 10:52:23 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@16c3ca31{/SQL/json,null,AVAILABLE,@Spark}
22/09/07 10:52:23 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e38d975{/SQL/execution,null,AVAILABLE,@Spark}
22/09/07 10:52:23 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@48ea2003{/SQL/execution/json,null,AVAILABLE,@Spark}
22/09/07 10:52:23 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@a50ae65{/static/sql,null,AVAILABLE,@Spark}
22/09/07 10:52:24 INFO InMemoryFileIndex: It took 168 ms to list leaf files for 1 paths.
22/09/07 10:52:26 INFO FileSourceStrategy: Pushed Filters: 
22/09/07 10:52:26 INFO FileSourceStrategy: Post-Scan Filters: 
22/09/07 10:52:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
22/09/07 10:52:26 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:26 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 285.9 KiB, free 2.9 GiB)
22/09/07 10:52:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 2.9 GiB)
22/09/07 10:52:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.122.1:35602 (size: 13.4 KiB, free: 2.9 GiB)
22/09/07 10:52:26 INFO SparkContext: Created broadcast 0 from rdd at SortTest.scala:46 zcp, execution time(ns) of creating broadcast 116056756
22/09/07 10:52:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 90512102 bytes, open cost is considered as scanning 4194304 bytes.
22/09/07 10:52:27 INFO SparkContext: Starting job: sortByKey at SortTest.scala:46
22/09/07 10:52:27 INFO DAGScheduler: Got job 0 (sortByKey at SortTest.scala:46) with 4 output partitions
22/09/07 10:52:27 INFO DAGScheduler: Final stage: ResultStage 0 (sortByKey at SortTest.scala:46)
22/09/07 10:52:27 INFO DAGScheduler: Parents of final stage: List()
22/09/07 10:52:27 INFO DAGScheduler: Missing parents: List()
22/09/07 10:52:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at sortByKey at SortTest.scala:46), which has no missing parents
22/09/07 10:52:27 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:27 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.1 KiB, free 2.9 GiB)
22/09/07 10:52:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 2.9 GiB)
22/09/07 10:52:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.122.1:35602 (size: 4.3 KiB, free: 2.9 GiB)
22/09/07 10:52:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1224 zcp, execution time(ns) of creating broadcast 7289903
22/09/07 10:52:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at sortByKey at SortTest.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/09/07 10:52:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
22/09/07 10:52:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.122.1, executor driver, partition 0, PROCESS_LOCAL, 7843 bytes)
22/09/07 10:52:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.122.1, executor driver, partition 1, PROCESS_LOCAL, 7843 bytes)
22/09/07 10:52:27 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.122.1, executor driver, partition 2, PROCESS_LOCAL, 7843 bytes)
22/09/07 10:52:27 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 192.168.122.1, executor driver, partition 3, PROCESS_LOCAL, 7843 bytes)
22/09/07 10:52:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
22/09/07 10:52:27 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
22/09/07 10:52:27 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
22/09/07 10:52:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
22/09/07 10:52:27 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:27 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:28 INFO CodeGenerator: Code generated in 204.761541 ms
22/09/07 10:52:28 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00001, range: 0-41061202, partition values: [empty row]
22/09/07 10:52:28 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00003, range: 0-41063350, partition values: [empty row]
22/09/07 10:52:28 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00004, range: 0-41060798, partition values: [empty row]
22/09/07 10:52:28 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00000, range: 0-41062559, partition values: [empty row]
22/09/07 10:52:28 INFO CodeGenerator: Code generated in 14.394668 ms
22/09/07 10:52:28 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:28 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:29 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00002, range: 0-41059727, partition values: [empty row]
22/09/07 10:52:29 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00005, range: 0-41061054, partition values: [empty row]
22/09/07 10:52:29 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00006, range: 0-41062985, partition values: [empty row]
22/09/07 10:52:29 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00007, range: 0-41062303, partition values: [empty row]
22/09/07 10:52:29 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 339534 bytes result sent to driver
22/09/07 10:52:29 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 2068 ms on 192.168.122.1 (executor driver) (1/4)
22/09/07 10:52:29 INFO MemoryStore: Block taskresult_0 stored as bytes in memory (estimated size 2.4 MiB, free 2.9 GiB)
22/09/07 10:52:29 INFO BlockManagerInfo: Added taskresult_0 in memory on 192.168.122.1:35602 (size: 2.4 MiB, free: 2.9 GiB)
22/09/07 10:52:29 INFO MemoryStore: Block taskresult_1 stored as bytes in memory (estimated size 1922.8 KiB, free 2.9 GiB)
22/09/07 10:52:29 INFO BlockManagerInfo: Added taskresult_1 in memory on 192.168.122.1:35602 (size: 1922.8 KiB, free: 2.9 GiB)
22/09/07 10:52:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2488657 bytes result sent via BlockManager)
22/09/07 10:52:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1968903 bytes result sent via BlockManager)
22/09/07 10:52:29 INFO MemoryStore: Block taskresult_2 stored as bytes in memory (estimated size 2.3 MiB, free 2.9 GiB)
22/09/07 10:52:29 INFO BlockManagerInfo: Added taskresult_2 in memory on 192.168.122.1:35602 (size: 2.3 MiB, free: 2.9 GiB)
22/09/07 10:52:29 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2366899 bytes result sent via BlockManager)
22/09/07 10:52:29 INFO TransportClientFactory: Successfully created connection to /192.168.122.1:35602 after 35 ms (0 ms spent in bootstraps)
22/09/07 10:52:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2237 ms on 192.168.122.1 (executor driver) (2/4)
22/09/07 10:52:29 INFO BlockManagerInfo: Removed taskresult_1 on 192.168.122.1:35602 in memory (size: 1922.8 KiB, free: 2.9 GiB)
22/09/07 10:52:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2266 ms on 192.168.122.1 (executor driver) (3/4)
22/09/07 10:52:29 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 2250 ms on 192.168.122.1 (executor driver) (4/4)
22/09/07 10:52:29 INFO BlockManagerInfo: Removed taskresult_0 on 192.168.122.1:35602 in memory (size: 2.4 MiB, free: 2.9 GiB)
22/09/07 10:52:29 INFO BlockManagerInfo: Removed taskresult_2 on 192.168.122.1:35602 in memory (size: 2.3 MiB, free: 2.9 GiB)
22/09/07 10:52:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
22/09/07 10:52:29 INFO DAGScheduler: ResultStage 0 (sortByKey at SortTest.scala:46) finished in 2.338 s
22/09/07 10:52:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
22/09/07 10:52:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
22/09/07 10:52:29 INFO DAGScheduler: Job 0 finished: sortByKey at SortTest.scala:46, took 2.388456 s
22/09/07 10:52:29 INFO SparkContext: Starting job: sortByKey at SortTest.scala:46
22/09/07 10:52:29 INFO DAGScheduler: Got job 1 (sortByKey at SortTest.scala:46) with 1 output partitions
22/09/07 10:52:29 INFO DAGScheduler: Final stage: ResultStage 1 (sortByKey at SortTest.scala:46)
22/09/07 10:52:29 INFO DAGScheduler: Parents of final stage: List()
22/09/07 10:52:29 INFO DAGScheduler: Missing parents: List()
22/09/07 10:52:29 INFO DAGScheduler: Submitting ResultStage 1 (PartitionwiseSampledRDD[10] at sortByKey at SortTest.scala:46), which has no missing parents
22/09/07 10:52:29 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:29 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.6 KiB, free 2.9 GiB)
22/09/07 10:52:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 2.9 GiB)
22/09/07 10:52:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.122.1:35602 (size: 4.6 KiB, free: 2.9 GiB)
22/09/07 10:52:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1224 zcp, execution time(ns) of creating broadcast 4948985
22/09/07 10:52:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PartitionwiseSampledRDD[10] at sortByKey at SortTest.scala:46) (first 15 tasks are for partitions Vector(0))
22/09/07 10:52:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
22/09/07 10:52:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, 192.168.122.1, executor driver, partition 0, PROCESS_LOCAL, 8049 bytes)
22/09/07 10:52:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
22/09/07 10:52:29 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:29 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:29 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00004, range: 0-41060798, partition values: [empty row]
22/09/07 10:52:29 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00002, range: 0-41059727, partition values: [empty row]
22/09/07 10:52:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 269973 bytes result sent to driver
22/09/07 10:52:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 411 ms on 192.168.122.1 (executor driver) (1/1)
22/09/07 10:52:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
22/09/07 10:52:30 INFO DAGScheduler: ResultStage 1 (sortByKey at SortTest.scala:46) finished in 0.420 s
22/09/07 10:52:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
22/09/07 10:52:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
22/09/07 10:52:30 INFO DAGScheduler: Job 1 finished: sortByKey at SortTest.scala:46, took 0.425458 s
22/09/07 10:52:30 INFO SparkContext: Starting job: count at SortTest.scala:48
22/09/07 10:52:30 INFO DAGScheduler: Registering RDD 5 (map at SortTest.scala:46) as input to shuffle 0
22/09/07 10:52:30 INFO DAGScheduler: Got job 2 (count at SortTest.scala:48) with 4 output partitions
22/09/07 10:52:30 INFO DAGScheduler: Final stage: ResultStage 3 (count at SortTest.scala:48)
22/09/07 10:52:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
22/09/07 10:52:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
22/09/07 10:52:30 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at map at SortTest.scala:46), which has no missing parents
22/09/07 10:52:30 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:30 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.5 KiB, free 2.9 GiB)
22/09/07 10:52:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 2.9 GiB)
22/09/07 10:52:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.122.1:35602 (size: 8.2 KiB, free: 2.9 GiB)
22/09/07 10:52:30 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1224 zcp, execution time(ns) of creating broadcast 5132447
22/09/07 10:52:30 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at map at SortTest.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/09/07 10:52:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks
22/09/07 10:52:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, 192.168.122.1, executor driver, partition 0, PROCESS_LOCAL, 7832 bytes)
22/09/07 10:52:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, 192.168.122.1, executor driver, partition 1, PROCESS_LOCAL, 7832 bytes)
22/09/07 10:52:30 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, 192.168.122.1, executor driver, partition 2, PROCESS_LOCAL, 7832 bytes)
22/09/07 10:52:30 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8, 192.168.122.1, executor driver, partition 3, PROCESS_LOCAL, 7832 bytes)
22/09/07 10:52:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
22/09/07 10:52:30 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
22/09/07 10:52:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
22/09/07 10:52:30 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
22/09/07 10:52:30 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:30 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:30 INFO ShuffleWriteProcessor: zcp, ShuffleWriteProcessor::write() is called.
22/09/07 10:52:30 INFO ShuffleWriteProcessor: zcp, ShuffleWriteProcessor::write() is called.
22/09/07 10:52:30 INFO ShuffleWriteProcessor: zcp, ShuffleWriteProcessor::write() is called.
22/09/07 10:52:30 INFO ShuffleWriteProcessor: zcp, ShuffleWriteProcessor::write() is called.
22/09/07 10:52:30 INFO ShuffleWriteProcessor: the class name of writer,org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter
22/09/07 10:52:30 INFO ShuffleWriteProcessor: the class name of writer,org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter
22/09/07 10:52:30 INFO ShuffleWriteProcessor: the class name of writer,org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter
22/09/07 10:52:30 INFO ShuffleWriteProcessor: the class name of writer,org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter
22/09/07 10:52:30 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00003, range: 0-41063350, partition values: [empty row]
22/09/07 10:52:30 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00001, range: 0-41061202, partition values: [empty row]
22/09/07 10:52:30 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00000, range: 0-41062559, partition values: [empty row]
22/09/07 10:52:30 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00004, range: 0-41060798, partition values: [empty row]
22/09/07 10:52:30 INFO BypassMergeSortShuffleWriter: zcp,BypassMergeSortShuffleWrite::2, numPartitions,4
22/09/07 10:52:30 INFO BypassMergeSortShuffleWriter: zcp,BypassMergeSortShuffleWrite::2, numPartitions,4
22/09/07 10:52:30 INFO BypassMergeSortShuffleWriter: zcp,BypassMergeSortShuffleWrite::2, numPartitions,4
22/09/07 10:52:30 INFO BypassMergeSortShuffleWriter: zcp,BypassMergeSortShuffleWrite::2, numPartitions,4
22/09/07 10:52:30 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:30 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:32 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00007, range: 0-41062303, partition values: [empty row]
22/09/07 10:52:32 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00005, range: 0-41061054, partition values: [empty row]
22/09/07 10:52:32 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00006, range: 0-41062985, partition values: [empty row]
22/09/07 10:52:32 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/HiBench/Wordcount/Input/part-m-00002, range: 0-41059727, partition values: [empty row]
22/09/07 10:52:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1711 bytes result sent to driver
22/09/07 10:52:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1711 bytes result sent to driver
22/09/07 10:52:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 4856 ms on 192.168.122.1 (executor driver) (1/4)
22/09/07 10:52:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 4855 ms on 192.168.122.1 (executor driver) (2/4)
22/09/07 10:52:35 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1668 bytes result sent to driver
22/09/07 10:52:35 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 4878 ms on 192.168.122.1 (executor driver) (3/4)
22/09/07 10:52:35 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 1668 bytes result sent to driver
22/09/07 10:52:35 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 4979 ms on 192.168.122.1 (executor driver) (4/4)
22/09/07 10:52:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
22/09/07 10:52:35 INFO DAGScheduler: ShuffleMapStage 2 (map at SortTest.scala:46) finished in 5.008 s
22/09/07 10:52:35 INFO DAGScheduler: looking for newly runnable stages
22/09/07 10:52:35 INFO DAGScheduler: running: Set()
22/09/07 10:52:35 INFO DAGScheduler: waiting: Set(ResultStage 3)
22/09/07 10:52:35 INFO DAGScheduler: failed: Set()
22/09/07 10:52:35 INFO DAGScheduler: Submitting ResultStage 3 (ShuffledRDD[11] at sortByKey at SortTest.scala:46), which has no missing parents
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.4 KiB, free 2.9 GiB)
22/09/07 10:52:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.9 GiB)
22/09/07 10:52:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.122.1:35602 (size: 5.0 KiB, free: 2.9 GiB)
22/09/07 10:52:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1224 zcp, execution time(ns) of creating broadcast 4079310
22/09/07 10:52:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (ShuffledRDD[11] at sortByKey at SortTest.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/09/07 10:52:35 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
22/09/07 10:52:35 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 9, 192.168.122.1, executor driver, partition 0, NODE_LOCAL, 7143 bytes)
22/09/07 10:52:35 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 10, 192.168.122.1, executor driver, partition 1, NODE_LOCAL, 7143 bytes)
22/09/07 10:52:35 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 11, 192.168.122.1, executor driver, partition 2, NODE_LOCAL, 7143 bytes)
22/09/07 10:52:35 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 12, 192.168.122.1, executor driver, partition 3, NODE_LOCAL, 7143 bytes)
22/09/07 10:52:35 INFO Executor: Running task 0.0 in stage 3.0 (TID 9)
22/09/07 10:52:35 INFO Executor: Running task 1.0 in stage 3.0 (TID 10)
22/09/07 10:52:35 INFO Executor: Running task 2.0 in stage 3.0 (TID 11)
22/09/07 10:52:35 INFO Executor: Running task 3.0 in stage 3.0 (TID 12)
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecName,zlib
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:35 INFO CompressionCodec$: createCodec,codecClass,org.apache.spark.io.ZlibCompressionCodec
22/09/07 10:52:35 INFO ShuffleBlockFetcherIterator: Getting 4 (37.0 MiB) non-empty blocks including 4 (37.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/09/07 10:52:35 INFO ShuffleBlockFetcherIterator: Getting 4 (38.0 MiB) non-empty blocks including 4 (38.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/09/07 10:52:35 INFO ShuffleBlockFetcherIterator: Getting 1 (3.3 MiB) non-empty blocks including 1 (3.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/09/07 10:52:35 INFO ShuffleBlockFetcherIterator: Getting 1 (3.6 MiB) non-empty blocks including 1 (3.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/09/07 10:52:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
22/09/07 10:52:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
22/09/07 10:52:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
22/09/07 10:52:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
22/09/07 10:52:35 INFO Executor: Finished task 1.0 in stage 3.0 (TID 10). 1305 bytes result sent to driver
22/09/07 10:52:35 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 10) in 539 ms on 192.168.122.1 (executor driver) (1/4)
22/09/07 10:52:35 INFO Executor: Finished task 2.0 in stage 3.0 (TID 11). 1305 bytes result sent to driver
22/09/07 10:52:35 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 11) in 590 ms on 192.168.122.1 (executor driver) (2/4)
22/09/07 10:52:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.122.1:35602 in memory (size: 8.2 KiB, free: 2.9 GiB)
22/09/07 10:52:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.122.1:35602 in memory (size: 4.6 KiB, free: 2.9 GiB)
22/09/07 10:52:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.122.1:35602 in memory (size: 4.3 KiB, free: 2.9 GiB)
22/09/07 10:52:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 9). 1348 bytes result sent to driver
22/09/07 10:52:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 9) in 3030 ms on 192.168.122.1 (executor driver) (3/4)
22/09/07 10:52:38 INFO Executor: Finished task 3.0 in stage 3.0 (TID 12). 1348 bytes result sent to driver
22/09/07 10:52:38 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 12) in 3029 ms on 192.168.122.1 (executor driver) (4/4)
22/09/07 10:52:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
22/09/07 10:52:38 INFO DAGScheduler: ResultStage 3 (count at SortTest.scala:48) finished in 3.042 s
22/09/07 10:52:38 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
22/09/07 10:52:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
22/09/07 10:52:38 INFO DAGScheduler: Job 2 finished: count at SortTest.scala:48, took 8.078470 s
24827
execution time(ms),18494
22/09/07 10:52:38 INFO AbstractConnector: Stopped Spark@1de5f0ef{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
22/09/07 10:52:38 INFO SparkUI: Stopped Spark web UI at http://192.168.122.1:4040
22/09/07 10:52:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
22/09/07 10:52:38 INFO MemoryStore: MemoryStore cleared
22/09/07 10:52:38 INFO BlockManager: BlockManager stopped
22/09/07 10:52:38 INFO BlockManagerMaster: BlockManagerMaster stopped
22/09/07 10:52:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
22/09/07 10:52:38 INFO SparkContext: Successfully stopped SparkContext
22/09/07 10:52:38 INFO ShutdownHookManager: Shutdown hook called
22/09/07 10:52:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-a4785b30-91ef-49ac-8ef7-8cbf0982f3fb
